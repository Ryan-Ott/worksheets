{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this worksheets is part of the [mlvu machine learning course](https://mlvu.github.io)<br>\n",
    "setting up your environment: https://bit.ly/3bzpn5C\n",
    "\n",
    "This worksheet assumes that you've seen the first Deep Learning lecture. If you're running the worksheet before that lecture, you may want to have a look at last year's video. You can find the video through the course website above.\n",
    "\n",
    "For this worksheet, we need to install Keras. Execute the cell below.\n",
    "\n",
    "Parts of this worksheet are based on the Keras [autoencoder tutorial](https://blog.keras.io/building-autoencoders-in-keras.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-macosx_10_14_x86_64.whl (217.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 217.4 MB 12 kB/s  eta 0:00:01    |██▊                             | 18.4 MB 5.7 MB/s eta 0:00:35     |█████████████████████▌          | 145.9 MB 1.8 MB/s eta 0:00:40\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/ryan/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ryan/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (41.2.0)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-macosx_10_10_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-macosx_10_9_x86_64.whl (13.0 MB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.22.2-cp38-cp38-macosx_10_14_x86_64.whl (17.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.6 MB 611 kB/s eta 0:00:011    |███████████▏                    | 6.1 MB 10.0 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-macosx_10_9_x86_64.whl (961 kB)\n",
      "\u001b[K     |████████████████████████████████| 961 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.11.2-py3-none-any.whl (17 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, wheel, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, typing-extensions, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.4\n",
      "    Uninstalling numpy-1.19.4:\n",
      "      Successfully uninstalled numpy-1.19.4\n",
      "    Running setup.py install for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.6.0 importlib-metadata-4.11.2 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 numpy-1.22.2 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 typing-extensions-4.1.1 wheel-0.37.1 zipp-3.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to see if the installation worked (loading tensorflow may take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 4: Deep Learning\n",
    "\n",
    "**Tensorflow** is a low-level deep learning framework. **Keras** is a frontend library that makes things a little easier to use. It implements most basic neural network architectures in a simple framework. \n",
    "\n",
    "Deep learning models are trained by gradient descent. These models are often so complex, that we don't want to have to work out the gradient ourselves. Keras and tensorflow allow the gradient to be computed automatically.\n",
    "\n",
    "As we perform computations, tensorflow remembers the _computation graph_ that we build up. When the time comes to compute the gradient, tensorflow can trace back over the computation graph (using the backpropagation algorithm) and work out all the required gradients.\n",
    "\n",
    "When we build models with Keras, all this is abstracted away, so we don't usually have to worry about it. When we want to do more complicated things than Keras is suited to, a more low-level library is required, like vanilla Tensorflow or Pytorch. The next worksheet focuses on Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with a simple neural network model\n",
    "\n",
    "Now, let's build a simple neural network. We'll start by loading the [MNIST data](https://en.wikipedia.org/wiki/MNIST_database) that we saw in the first lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n",
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape) \n",
    "print(x_test.shape)\n",
    "\n",
    "print(type(x_train)) # note that these are just numpy arrays, no special tensorflow objects yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data is already split in a canonical train and test set. The training set is one 3D numpy array (a 3-tensor) of 60000 images of 28x28 pixels. The test set contains 10000 additional images.\n",
    "\n",
    "We'll define a simple function to have a look at the images in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x8640 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_digits(data):\n",
    "    \n",
    "    if(len(data.shape)==4):\n",
    "        data = data.squeeze(3)\n",
    "        \n",
    "    n, w, h = data.shape\n",
    "    \n",
    "    plt.figure(figsize=(12, 12*n))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1,n, i+1)\n",
    "        plt.imshow(data[i], cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "# use the function to plot the first 10 digits (together with the training labels)\n",
    "plot_digits(x_train[:10, :, :])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first network, we don't care about the structure of the image, so we'll [flatten](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy.reshape) everything into a 784-dimensional feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, -1)\n",
    "x_test = x_test.reshape(10000, -1)\n",
    "\n",
    "print(x_train.shape) \n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we'll use is a simple fully connected feedforward network. This is called a [Dense layer](https://keras.io/layers/core/#dense) in Keras. Since fully connected layers are a bit heavy on image data (and you're probably running this on your laptop), we'll reduce the dimensionality of the data by PCA (see the [Methodology 2](https://youtu.be/csk2HSWS5r8) lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=60) # reduce to 60 dimensions\n",
    "pca.fit(x_train)\n",
    "\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "print(x_train.shape) \n",
    "print(x_test.shape) \n",
    "\n",
    "# NB: none of this is Keras yet. We're just using sklearn on some numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training labels are encoded as integers. We need these as one-hot vectors instead, so we can match them to the ten outputs of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are now encoded as _one-hot vectors_: vectors of length 10 with zeros everywhere, except at the true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0]) # print the one-hot vector for the first example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to create a model. Keras has two APIs for this: the **Sequential API** and the **Model API**. The sequential API (the simplest) assumes that your model is a simple sequence of operations, usually neural network layers. The input is passed through the first layer, the result of that is passed through the second and so on. \n",
    "\n",
    "Note that it's the _model_ that is sequential, not the data. We are not dealing with sequential data (like language) here.\n",
    "\n",
    "This is useful for simple NN models where you are only interested in the input and output. If your model gets more complex, you may want to use the Model API (we'll discuss that below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(60,))) # first dense layer, 32 hidden units\n",
    "model.add(Activation('relu'))            # activation layer\n",
    "model.add(Dense(10))                     # second dense layer\n",
    "model.add(Activation('softmax'))         # output class probabilities\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to note:\n",
    "\n",
    "* For the first layer we need to provide the input shape. For the second, this is not necessary, because Keras can _infer_ the input shape from the layers before it.\n",
    "* The Dense layers are just linear operations (multiply by a weight matrix, add a bias vector). The activation functions are added as separate layers (activation_1, and activation_2). You can also pass the activation as an argument to the Dense layer.\n",
    "* Keras picks a sensible default weight initialization for us, and applies it (this model already has initial weights).\n",
    "* The last layer has 10 nodes (one for each class) with a softmax activation. This means we can interpret the output as class probabilities.\n",
    "* Even though we specified a one-dimensional input, the model summary shows two-dimensional shapes with the first dimension always ```None```. This is the _batch dimension_. Neural networks are almost never trained/run one input at a time; we usually feed them several inputs together (a mini-batch). So, if we choose a batch size of ten, our input dimension would become (10, 60 ) and our first hidden layer would have dimensions (10, 32). Keras can be flexible about the batch size so we don't have to specify it now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a complete computation graph, we need more than just a model: we need a loss function as well. We also need to specify which optimizer we're going to use. \n",
    "\n",
    "Let's use categorical cross-entropy as loss, together with the _Adam_ optimizer. All Keras' [optimizers](https://keras.io/optimizers/) are variations on gradient descent. Adam is a good default choice.\n",
    "\n",
    "With this information, we can compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "optimizer = Adam(lr=0.001) # lr is the learning rate\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've also told the compiler that we'd like it to compute accuracy for us during training (since categorical cross-entropy is a bit hard to interpret).\n",
    "\n",
    "We're now ready to start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my laptop (no GPU), this takes about 3 to 5 seconds per epoch (an epoch is a pass over the whole data).\n",
    "\n",
    "Note that these losses/accuracies are on the training data, so we can't tell if we're overfitting. Of course, **we don't want to use the test data at this stage to see how well we're doing**. We can tell Keras to withhold some validation data, so we can get an indication of the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=1/6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I end up with a validation accuracy of about 96%. Note that the model remembers its weights between cells so we've now trained it for 10 epochs, not 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Apparently, kNN with 60 dimensional PCA'd MNIST [can get an accuracy of 97.5%](http://bradleymitchell.me/?p=102), so we're doing ok. Let's see if we can do better with a convolutional neural net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A ConvNet for classification\n",
    "\n",
    "What deep neural networks really excel at, is _making use of all the data_. We've denied our neural network that by reducing the features with PCA. This time, we'll train a network on the complete images, but we'll use a sparsely connected network, a so called convolutional neural net. See the _Deep Learning 1_ lecture for more information.\n",
    "\n",
    "First, we'll reload the data, to undo our PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(x_train.shape) \n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we'll _keep the shape_. Keras needs that information to know how to wire up the Convolutional layers.\n",
    "\n",
    "Keras expects images to be 3-tensors with dimensions width, height, _channels_. Even though our images are grayscale, so have only one channel, the dimension still needs to be there. We'll add a dimension to the test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:, :, :, None]\n",
    "x_test  = x_test[:, :, :, None]\n",
    "\n",
    "print(x_train.shape) \n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our network (inspired by [this keras example](https://keras.io/examples/vision/mnist_convnet/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) # Dropout 25% of the nodes of the previous layer during training\n",
    "model.add(Flatten())     # Flatten, and add a fully connected layer\n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax')) # Last layer: 10 class nodes, with dropout\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have about half a million parameters. With a strong optimizer like Adam, and a big dataset like MNIST, this shouldn't be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(x_train, y_train, epochs=15, batch_size=32, validation_split=1/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a little slower than the previous network (around 50 seconds per epoch on my machine), but worth waiting for. After just one epoch, the validation accuracy is already ~97%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "\n",
    "The real fun of deep learning comes from building things that are not traditional classifiers, but that put the deep learning building blocks to another use. A simple example is an auto-encoder. We only discuss autoencoders in the _Deep Learning 2_ lecture, but the principle is simple: we want the neural network to reconstruct its input, but one of the layers in the middle is very small.\n",
    "\n",
    "For this, we'll ditch the Sequential API and go for the <em>Model API</em>. It's a little more complex, and a lot more powerful.\n",
    "\n",
    "First, we'll reload the data again. This time, we need to rescale the pixel values to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[:, :, :, None]\n",
    "x_test  = x_test[:, :, :, None]\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll build an encoder that maps the data to a small vector of just two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dense, Reshape, MaxPooling2D, UpSampling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "hidden_size = 2 # very small hidden size for an autoencoder, but it lets us plot the results\n",
    "\n",
    "input = Input(shape=(28,28,1))\n",
    "\n",
    "x = Conv2D(4, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1))(input)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (4, 4), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (4, 4), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(hidden_size)(x)\n",
    "\n",
    "encoder = Model(input, x)\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder takes the input and transforms it (through some convolutions) to a 2D point. Note that:\n",
    "\n",
    "* We are building a computation graph before seeing the data: we start with a placeholder (the ```Input```), and apply several transformations to it. At the end, the object ```x``` holds the whole computation graph. We then specify that our model consists of this computation graph, uses the placeholder node ```input``` as its input and uses ```x``` as its output.\n",
    "* We no longer need to store the sequence of layers. By the end, everything is stored inside x. We can create a layer, apply it and forget about it.\n",
    "\n",
    "We also define a <em>decoder</em>, which does the opposite: it starts with a 2D point (usually the output of our encoder), and transforms it back to an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = Input(shape=(hidden_size,))\n",
    "\n",
    "x = Dense(128)(encoded)\n",
    "x = Reshape((4,4,8))(x)\n",
    "\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(2, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "decoder = Model(encoded, decoded)\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete autoencoder now just consists of applying first the encoder model, and then the decoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = Model(input, decoder(encoder(input)))\n",
    "\n",
    "auto.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use models as components in other models: we build the complete autoencoder by combining the encoder and the decoder. The nice thing here is that we can use the model ```auto``` for training, and then use the encoder and decoder separately to play around with the trained model.\n",
    "\n",
    "\n",
    "We train the autoencoder with binary cross-entropy (each pixel is seen as a probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# This gives depracation warning, ignore that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the model, we provide it with the training data both as input and output (this is what makes it an autoencoder). This time we're not worried about overfitting, so we don't need a validation set. The better our model reconstructs the data, the happier we are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.fit(x_train, x_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes around one minute per epoch on my machine (so you may want to get a cup of coffee while it runs). If you're in a hurry, the rest of the worksheet also works if you stop it after two epochs.\n",
    "\n",
    "Let's run some test images through the autoencoder, and see what the reconstructions look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = x_test[:10, :, :, :]\n",
    "outputs = auto.predict(inputs)\n",
    "\n",
    "plot_digits(inputs)\n",
    "plot_digits(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstructions are far from perfect, but remember that we've reduced the whole image to just two numbers, and then reconstructed it.\n",
    "\n",
    "Since the latent space of of this autoencoder is 2D, we can plot what the data looks like in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5000\n",
    "\n",
    "inputs = x_test[:num, :, :, :]\n",
    "latent = encoder.predict(inputs)\n",
    "\n",
    "plt.scatter(latent[:,0], latent[:,1], c=y_test[:num], alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've colored the points by class, but remember that the autoencoder has no access to the class labels. The structure  you see here was learned purely from the pixel values. With more training (and a more powerful model), it's possible to get almost complete separation of the classes.\n",
    "\n",
    "A final trick we can do with encoder models, is to _interpolate in the latent space_. We pick two encoded examples, draw a line between them, and decode points spaced equally on that line. This will give us a slow tranformation from one example to the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Two random digits, try changing the indices to see what happens\n",
    "example1 = x_test[190,:,:,:] \n",
    "example2 = x_test[237,:,:,:]\n",
    "\n",
    "l1, l2 = encoder.predict(example1[None, :,:,:]), encoder.predict(example2[None, :,:,:])\n",
    "#-- we add the None, because keras expects a batch dimension (even if the batch size is 1)\n",
    "\n",
    "# ten points, equally spaced between 0 and 1\n",
    "line = np.linspace(0, 1, 10)[:, None]\n",
    "\n",
    "points = l1 * line + l2 * (1-line)\n",
    "\n",
    "# Plot the points we will decode\n",
    "plt.scatter(latent[:,0], latent[:,1], c=y_test[:num], alpha=0.01)\n",
    "plt.scatter(points[:, 0], points[:, 1])\n",
    "\n",
    "outputs = decoder.predict(points)\n",
    "plot_digits(outputs.squeeze(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may not yet look very convincing if you stoppped training early.\n",
    "\n",
    "It works best if the decoding looks good (which is difficult to achieve with this model, relatively little training, and a 2D latent space). \n",
    "\n",
    "Try setting the latent space higher: increase ```hidden_size``` above  to something like 64. Rebuild the model and rerun the experiment. The plots above will still work, but they will only show the first two dimensions of a 64-dimensional latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments\n",
    "\n",
    "As before, we have given you hopefully just enough to get you started, but there is much more to learn. This means that once you start trying things, you will almost certainly get stuck. Feel free to ask questions on the discussion board, we'll do our best to help. \n",
    "\n",
    "Some recommendations:\n",
    "* Plot your [loss curves](). We recommend using Tensorboard to monitor your training, which integrates well with Keras.\n",
    "* The most important hyperparameters to tweak are probably _batch size_, _learning rate_ and _number of hidden units_.\n",
    "* It's likely that at some point [your loss function will suddenly become NaN](http://russellsstewart.com/notes/0.html) (not a number). This often happens when one of the units somewhere in your network gets very big (close to infinite). This causes the loss to become infinite for, which gives NaN for the gradient. Keras still continues with the backpropagation, and the whole network becomes NaN. Usually, it help to reduce the learning rate or to increase the number of hidden units. If not, you should train your model one batch at a time by calling model.train_on_batch(), printing the weights after each batch. This allows you to see what happens just before the loss becomes NaN, which may give you a hint as to what is happening.\n",
    "* As you can see, even training a medium-size network can take a long time, especially if you don't have access to a GPU. One trick you can try is [transfer learning](https://towardsdatascience.com/transfer-learning-using-keras-d804b2e04ef8). Using a model that somebody else has trained, and building on top of it. This allows you to use the power of a deep network, while only training a few layers yourself. The VGG network, which Keras can download for you, is a particularly good choice.\n",
    "* If you want to compare Keras models against other classifiers or regression methods, Keras [integrates with sklearn](https://keras.io/scikit-learn-api/).\n",
    "* For modest networks, you should be able to just let your laptop run overnight to perform experiments. If you want a little more power, you'll need a GPU.\n",
    " * [Google Colab](https://colab.research.google.com) is a cloud-based notebook environment based on Jupyter. It's easy to request a GPU and run your notebook based experiments in there,\n",
    " * Google Cloud Compute has [a 300$ free tier](https://hackernoon.com/launch-a-gpu-backed-google-compute-engine-instance-and-setup-tensorflow-keras-and-jupyter-902369ed5272), that should be enough to run experiments for this course (especially if everybody n your group signs up). Making mistakes in cloud computing can be costly, so be sure to do the following:\n",
    " * Make sure the machine turns off after each experiment.\n",
    " * Set up budget limits and alerts so you realize quickly if you're running our of credit.\n",
    " * Keep your private key and signup email _extremely_ private. If, for instance, you accidentally put this on github, it will get crawled almost immediately and someone will set up a bitcoin miner on your credit.\n",
    "\n",
    "Here are some good resources to read first:\n",
    "* [37 reasons why your neural network is not working](https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607)\n",
    "* [25 Must Know Terms & concepts for Beginners in Deep Learning](https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners-in-deep-learning/)\n",
    "* [Directory of Keras tutorials and other resources](https://github.com/fchollet/keras-resources)\n",
    "* [CS231n](http://cs231n.stanford.edu/) A famous Stanford course on computer vision with deep neural networks. The level is a little higher than our course, but they also deal with the practicalities of deep learning a lot better.\n",
    "* [DLVU](https://dlvu.github.io) Our own deep learning course. It's an MSc course, so the level is a little higher, but the first few lectures shouldn't be too difficult too follow, and they'll give you a lot more detail.\n",
    "\n",
    "Happy Learning!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
